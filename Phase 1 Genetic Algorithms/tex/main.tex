% Exercise Template
%A LaTeX template for typesetting exercise in Persian (with cover page).
%By: Zeinab Seifoori

\documentclass[12pt]{exam}

\usepackage{setspace}
\usepackage{listings}
\usepackage{xcolor}

% Define colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


% Configure listings style
\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize\setLTR,
	breakatwhitespace=true,         
	breaklines=true,                 
	captionpos=top, % Changed to top placement
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2,
	frame=single,
	abovecaptionskip=5pt, % Space between caption and code
	belowcaptionskip=5pt, % Space between code and potential bottom text
}


\lstset{style=mystyle}

% Set Persian caption for listings
\renewcommand{\lstlistingname}{برنامه}

\usepackage{graphicx,subfigure,wrapfig}
\usepackage{float} %for floating shapes

\usepackage{multirow}
%\usepackage{multicol}


%%%%%%%%%  for pie chart %%%%%
\usepackage{pgf-pie}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[margin=20mm]{geometry}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
	pdftitle={Overleaf Example},
	pdfpagemode=FullScreen,
}
\usepackage{xepersian}
\settextfont{XB Niloofar}

\newcommand{\class}{درس مبانی هوش محاسباتی}
\newcommand{\term}{نیم‌سال دوم ۰۱-۰۲}
\newcommand{\college}{دانشکده مهندسی کامپیوتر}
\newcommand{\prof}{استاد: دکتر کارشناس}

\onehalfspacing
\parindent 0ex
\begin{document}
	
	\include{info}
	\pagestyle{empty}
	\include{cover-page}
	
	% These commands set up the running header on the top of the exam pages
	\pagestyle{head}
	\firstpageheader{}{}{}
	\runningheader{صفحه \thepage\ از \numpages}{}{\class}
	\runningheadrule
	%\begin{tabular}{p{.7\textwidth} l}
	%\multicolumn{2}{c}{\textbf{به نام خدا}}\\
	%\multirow{2}{*}{\includegraphics[scale=0.2] {images/logo.png}} & \\ \\
	%&  \textbf{\class}\\
	%&  \textbf{\term}\\
	%&  \textbf{\prof}\\ \\
	% \textbf{\college} &  \\
	%\end{tabular}\\
	
	%\rule[1ex]{\textwidth}{.1pt}
	%\textbf{تمرین سری پنجم}
	
	%\rule[1ex]{\textwidth}{.1pt}
	%\makebox[45mm]{\hrulefill}\\
	\tableofcontents
	\vspace{1cm}
	\setcounter{section}{-1}
	\section{مقدمه}
	هدف از این تمرین آشنایی بیشتر با الگوریتم‌های ژنتیک و استفاده‌ی بیشتر از آن‌ها در کاربردهای عملی است.
	
	\section{مبانی و مفاهیم الگوریتم ژنتیک}
	\begin{questions}
		\question
		\textbf{ 
			تعریف الگوریتم تکاملی: }
		بر اساس مقاله مذکور در تمرین درس، الگوریتم‌های تکاملی 
		(\lr{Evolution Strategies})
		یک کلاس از الگوریتم‌های بهینه‌سازی جعبه سیاه هستند که رویه‌های جستجوی اکتشافی الهام‌گرفته از تکامل طبیعی هستند. در هر تکرار (نسل) یک جمعیت از بردارهای پارامتر (ژنوتیپ) آشفته (جهش) می‌شوند و مقدار تابع هدف 
		\lr{(Fitness function)}
		آن‌ها ارزیابی می‌شود. سپس بردارهای پارامتر با بالاترین امتیاز برای تشکیل جمعیت نسل بعدی ترکیب می‌شوند و این رویه تا زمانی که هدف به طور کامل بهینه شود، تکرار می‌شود.
		
		بر اساس مقاله، مزایای اصلی الگوریتم‌های تکاملی (ES) نسبت به الگوریتم‌های یادگیری تقویتی (RL) در برخی مسائل شامل موارد زیر است:
		\begin{enumerate}
			\item \textbf{
				موازی‌سازی بالا و کاهش هزینه محاسباتی:}
			الگوریتم‌های تکاملی به طور طبیعی قابلیت موازی‌سازی بالایی دارند. با استفاده از یک استراتژی ارتباطی مبتنی بر اعداد تصادفی مشترک، این الگوریتم‌ها توانسته‌اند تنها با ارسال مقادیر اسکالر میان کارگران موازی (واحدهای پردازشی مستقل که در یک سیستم توزیع‌شده یا موازی کار می‌کنند تا بخشی از محاسبات را انجام دهد.)، به‌سرعت به بیش از هزار کارگر موازی مقیاس‌پذیر شود. این امر باعث می‌شود که
			\lr{ES}
			در مقایسه با روش‌های یادگیری تقویتی مانند
			\lr{ Policy Gradients}
			که نیاز به ارسال گرادیان‌های کامل دارند، نیاز به پهنای باند بسیار کمتری داشته باشد. مقیاس‌پذیری بالا باعث می‌شود که
			\lr{ ES}
			بتواند مسائل پیچیده؛ مانند راه‌رفتن انسان‌نمای سه‌بعدی را در مدت‌زمان کوتاه 10 دقیقه ای حل کند. به طور خلاصه :
			\begin{itemize}
				\item  
				روش‌های
				\lr{ES}
				به دلیل عدم نیاز به پس انتشار گرادیان 
				(\lr{Backpropagation})
				به‌راحتی در سیستم‌های توزیع‌شده اجرا می‌شوند.
				\item 
				ارتباطات بین پردازنده‌ها در
				\lr{ES}
				بسیار کم‌حجم‌تر از
				\lr{RL}
				است، زیرا فقط یک مقدار اسکالر ارسال می‌شود، درحالی‌که
				\lr{ RL} 
				نیاز به ارسال گرادیان‌های کامل دارد.
				\item 
				این الگوریتم‌ها امکان اجرای هم‌زمان روی هزاران پردازنده را فراهم می‌کنند که در برخی آزمایش‌ها باعث کاهش زمان یادگیری از ساعت‌ها به چند دقیقه شده است.
				
			\end{itemize}
			\item \textbf{
				عدم نیاز به تابع ارزش 
				\lr{(Value Function)} 
				و کاهش پیچیدگی مدل: 
			}
			این الگوریتم‌ها نیازی به تخمین تابع ارزش ندارند. درحالی‌که بسیاری از الگوریتم‌های
			\rl{RL} مانند
			\lr{ Q-learning} و \lr{Policy Gradients}
			به تخمین تابع ارزش وابسته هستند. این امر باعث می‌شود که ES از نظر محاسباتی سبک‌تر باشد و نیاز به حافظه کمتری داشته باشد. عدم نیاز به تخمین تابع ارزش باعث می‌شود که ES در مواجهه با پاداش‌های بسیار پراکنده یا تأخیر دار عملکرد بهتری داشته باشد. به طور خلاصه:
			\begin{itemize}
				
				\item
				بسیاری از روش‌های RL مانند یادگیری سیاست 
				\lr{(Policy Gradient)}
				برای بهبود عملکرد نیاز به تخمین تابع ارزش دارند که محاسبات را پیچیده و وابسته به هایپرپارامترها می‌کند.
				\item ES  مستقیماً پارامترهای سیاست را جستجو می‌کند و نیازی به تابع ارزش ندارد.
			\end{itemize}
			\item \textbf{مقاومت در برابر افق‌های زمانی طولانی و پاداش‌های تأخیری:}
			این الگوریتم‌ها به دلیل اینکه تنها از بازده کل یک اپیزود استفاده می‌کند، نسبت به تأخیر در پاداش‌ها و افق‌های زمانی طولانی مقاوم است. این در حالی است که روش‌های RL مانند
			\lr{ Policy Gradients}
			ممکن است به دلیل نیاز به تخمین تابع ارزش و تأثیرات بلندمدت اقدامات، در مواجهه با افق‌های زمانی طولانی دچار مشکل شوند. به طور خلاصه:
			\begin{itemize}
				\item 
				در RL، مقداردهی تنزیلی (Discounting) و تابع ارزش برای مدیریت پاداش‌های تأخیری استفاده می‌شود که در مسائل با افق‌های زمانی بلند (مانند تصمیم‌گیری استراتژیک) ممکن است منجر به یادگیری نامناسب شود.
				\item  ES 
				
				مستقیماً بر بهینه‌سازی کل اپیزود تمرکز دارد و نیازی به کاهش‌دادن پاداش ندارد، بنابراین در مسائل با وابستگی‌های بلندمدت کارآمدتر است.
				\end{itemize}
				\item \textbf{کاوش بهتر و متنوع‌تر نسبت به روش‌های مبتنی بر گرادیان: }
				روش‌های مبتنی بر گرادیان مانند RL تمایل دارند که در مینیمم‌های محلی گیر بیفتند و در بسیاری از موارد به بهینه سراسری نرسند. ES با تغییر پارامترهای سیاست به‌صورت تصادفی، رفتارهای جدید و غیرمنتظره را تولید می‌کند که در برخی آزمایش‌ها، منجر به یادگیری انواع راه‌حل‌های جدید (مانند سبک‌های مختلف راه‌رفتن در شبیه‌سازی ربات‌ها) شده است.
				\item \textbf{عدم وابستگی به نرخ فریم 
				\lr{(Frame-Skip)}
				و فرکانس اقدامات:}
				در یادگیری تقویتی، نرخ فریم و نرخ انجام اقدام نقش مهمی در موفقیت یادگیری دارد. ES  نسبت به فرکانس اقدامات 
				\lr{(Action Frequency)}
				بی‌تفاوت است، درحالی‌که در روش‌های
				\lr{RL}
				، تنظیم فرکانس اقدامات 
				\lr{(Frame-skip)}
				یک پارامتر حیاتی است که می‌تواند به طور قابل‌توجهی بر عملکرد الگوریتم تأثیر بگذارد.
				\item\textbf{ عدم نیاز به تخفیف زمانی \lr{(Temporal Discounting)}:}
				ES نیازی به اعمال تخفیف زمانی روی پاداش‌ها ندارد، درحالی‌که بسیاری از روش‌های RL برای کاهش واریانس گرادیان‌ها، از تخفیف زمانی استفاده می‌کنند. این امر می‌تواند باعث ایجاد مشکل در تخمین گرادیان‌ها شود، به‌ویژه زمانی که اقدامات تأثیرات بلندمدت دارند.
				\item \textbf{
				عدم نیاز به محاسبه گرادیان‌ها: 
				}
				نیازی به محاسبه گرادیان‌ها از طریق backpropagation ندارد، این امر باعث کاهش حجم محاسبات و حافظه مورد نیاز می‌شود. همچنین، این ویژگی باعث می‌شود که ES در مواجهه با شبکه‌های عصبی با گرادیان‌های منفجرشده
				\lr{(Exploding Gradients)} مقاوم‌تر باشد.
				\item \textbf{امکان استفاده از شبکه‌های عصبی غیرقابل‌تفکیک و سخت‌افزارهای کم‌دقت: }
				در
				\lr{RL}،
				به دلیل نیاز به محاسبه گرادیان، معماری شبکه عصبی باید مشتق‌پذیر باشد. اما در
				\lr{ES}،
				می‌توان از معماری‌هایی که غیرقابل‌تفکیک هستند (مانند توجه سخت یا شبکه‌های باینری) نیز استفاده کرد. این روش همچنین برای سخت‌افزارهای محاسباتی کم‌دقت مانند TPU مناسب است.
			\end{enumerate}
		\question الگوریتم ژنتیک (GA) یک روش بهینه‌سازی و جستجو است که بر اساس اصول تکامل طبیعی داروین، مانند انتخاب طبیعی، جهش (Mutation) و ترکیب (Crossover)، عمل می‌کند. این الگوریتم از یک جمعیت از راه‌حل‌های ممکن (کروموزوم‌ها) شروع کرده و با اعمال رفتارهای تکاملی، نسل‌های جدیدی ایجاد می‌کند تا در نهایت به یک جواب بهینه یا نزدیک بهینه برسد.
		\newline \newline
		مراحل الگوریتم ژنتیک:
		\begin{enumerate}
			\item \textbf{ایجاد جمعیت اولیه:}
			مجموعه‌ای از کروموزوم‌های تصادفی ایجاد می‌شود.
			\item \textbf{محاسبه تابع برازندگی (\lr{Fitness Function}):}
			هر کروموزوم ارزیابی می‌شود تا میزان مناسب‌بودن آن برای حل مسئله مشخص شود.
			\item \textbf{	انتخاب (\lr{Selection}):}
			کروموزوم‌هایی که مقدار برازندگی بهتری دارند، شانس بیشتری برای تولید نسل بعدی به‌عنوان والد خواهند داشت.
			
			\item \textbf{	ترکیب (\lr{Crossover}):}
			دو کروموزوم والد با یکدیگر ترکیب شده و فرزندان جدیدی تولید می‌کنند.
			
			
			\item \textbf{	جهش (\lr{Mutation}): }
			به‌صورت تصادفی تغییراتی در برخی کروموزوم‌ها اعمال می‌شود تا تنوع حفظ شود.
			
			\item \textbf{تکرار فرایند: }
			این فرایند تا رسیدن به یک معیار توقف، مانند رسیدن به یک جواب بهینه یا پایان‌یافتن تعداد نسل‌ها ادامه می‌یابد (به‌عنوان شرط حلقه\lr{while}
			 به‌عنوان‌مثال در پیاده‌سازی
			 ).
			
		\end{enumerate}
		
		تفاوت الگوریتم ژنتیک (GA) با الگوریتم برنامه‌نویسی تکاملی (EP) و استراتژی‌های تکاملی (ES):
	

\begin{table}[H]
\centering
\begin{tabular}{|p{2.5cm}|p{4cm}|p{4cm}|p{4cm}|}
\hline
\textbf{ویژگی} & \textbf{الگوریتم ژنتیک (GA)} & \textbf{برنامه‌نویسی تکاملی (EP)} & \textbf{استراتژی‌های تکاملی (ES)} \\ \hline
\textbf{
	نمایش راه‌حل‌ها} & کروموزوم‌ها معمولاً رشته‌های باینری، اعداد یا کدگذاری خاص دارند. & هر فرد به‌عنوان یک استراتژی مستقل نمایش داده می‌شود. & بردارهای عددی با پارامترهای تصادفی نمایش داده می‌شوند. \\ \hline
\textbf{عملگرهای تکاملی}
& ترکیب (Crossover) و جهش (Mutation) & تمرکز بیشتر بر جهش، ترکیب کمتر مورد استفاده قرار می‌گیرد. & بیشتر از جهش استفاده شده و ترکیب محدود است. \\ \hline
\textbf{کاربردها}
& مسائل عمومی مانند بهینه‌سازی، یادگیری ماشین، مهندسی و... & مسائل مرتبط با یادگیری و مدل‌سازی هوش مصنوعی & مسائل عددی، بهینه‌سازی پارامترها و کنترل تطبیقی  \\ \hline
\textbf{نحوه انتخاب والدین}
& انتخاب بر اساس تابع برازندگی & انتخاب تصادفی با احتمال بیشتر برای افراد بهتر & انتخاب بر اساس مقایسه مستقیم عملکرد فردی \\ \hline
\textbf{نحوه ایجاد نسل جدید} 
& ترکیب و جهش کروموزوم‌ها برای تولید فرزندان جدید & فقط جهش روی هر فرد اعمال می‌شود & استفاده از بردارهای تصادفی برای تغییر مقدار پارامترها\\ \hline
\end{tabular}
\caption{مقایسه‌ی الگوریتم‌های ژنتیک با برنامه‌نویسی تکاملی و استراتژی تکاملی}
\end{table}
\newpage

	\question
	\begin{parts}
		\part
	 در مورد رشته‌های بیتی (\lr{Bitstring})، استفاده از عملگرهای الگوریتم به شکل زیر است:
	
	\begin{enumerate}
		\item \textbf{ترکیب (\lr{Crossover}):}
		عملیات ترکیب برای تولید فرزندان جدید از والدین انجام می‌شود. رایج‌ترین روش‌های ترکیب در رشته‌های بیتی عبارت‌اند از:
		\begin{itemize}
			\item \textbf{  ترکیب تک‌نقطه‌ای (\lr{Single-Point Crossover}): }
			یک نقطه تصادفی در رشته والدین انتخاب شده و بخش‌های قبل و بعد از آن بین دو والد جابه‌جا می‌شوند. 
			\newline
			مثال:  
			\newline
			والد اول: 1100 | 101              والد دوم: 0011 | 011
			
			\item \textbf{ترکیب دو‌نقطه‌ای (\lr{Two-Point Crossover}): }
			دونقطه تصادفی انتخاب شده و بخش میانی رشته بین دو والد جابه‌جا می‌شود. 
			\newline
			مثال:
			
			
			\item \textbf{ترکیب یکنواخت (\lr{Uniform Crossover}): }
			هر بیت از هر والد با احتمال ۵۰٪ برای فرزند انتخاب می‌شود. 
			\newline
			مثال:
		\end{itemize}
		\item \textbf{جهش (\lr{Mutation}):}
		عملیات جهش معمولاً برای حفظ تنوع در جمعیت و جلوگیری از همگرایی زودرس انجام می‌شود.
		متداول‌ترین روش برای جهش در رشته‌های بیتی، معکوس کردن بیت‌ها (\lr{Bit Flip Mutation}) است که با یک احتمال مشخص (معمولاً مقدار کوچکی مانند \lr{0.01} یا \lr{0.05})، برخی از بیت‌های رشته به مقدار مخالف خود تغییر می‌کنند. 
		\newline
		مثال:
		\newline
		رشته اصلی:101110 
		\newline
		پس از جهش: 100010 (دو بیت سوم و چهارم از سمت راست تغییر کرده اند.)
		
	\end{enumerate}
	\part
	زمانی که از جای‌گشت‌ها (\lr{Permutations}) یا نمایش‌های غیر باینری در الگوریتم ژنتیک (GA) استفاده می‌شود، عملیات ترکیب (\lr{Crossover}) و جهش (Mutation) باید به‌گونه‌ای اصلاح شوند که ویژگی‌های جای‌گشتی را حفظ کنند.
	\begin{enumerate}
		\item \textbf{عملگر ترکیب (Crossover) برای جای‌گشت‌ها:}
		در جای‌گشت‌ها، هر مقدار باید یک‌بار و فقط در یک موقعیت ظاهر شود. در نتیجه، روش‌های ترکیب رشته‌های بیتی که منجر به مقادیر تکراری یا حذف‌شده می‌شوند، نامناسب‌اند. روش‌های ترکیب مناسب عبارت‌اند از:
		\begin{itemize}
			\item \textbf{ترکیب جزئی همپوشان (\lr{Partially Mapped Crossover - PMX}):}
			دونقطه تصادفی در والدین انتخاب می‌شوند.
			بخش بین این دونقطه بین والدین جابه‌جا می‌شود.
			باقی‌مانده مقادیر با استفاده از یک نگاشت تنظیم می‌شود تا جای‌گشت معتبر بماند.
			\newline
			مثال:
			
			\item \textbf{ترکیب ترتیب یافته (\lr{Order Crossover - OX}):}
			یک بخش تصادفی از والد اول انتخاب و در فرزند کپی می‌شود.
			مقادیر باقی‌مانده از والد دوم به همان ترتیب قرار می‌گیرند.
			\newline
			مثال:
			
			\item \textbf{ترکیب چرخه‌ای (\lr{Cycle Crossover - CX}):}
			مقادیر در چرخه‌هایی بین والدین حفظ می‌شوند تا ترتیب کلی جای‌گشت رعایت شود.
			\newline
			مثال:
			
		\end{itemize}
		\item \textbf{عملگر جهش (Mutation) برای جای‌گشت‌ها:}
		در جای‌گشت‌ها، نباید تکرار یا حذف اعداد رخ دهد. پس جهش به‌صورت تغییر ترتیب مقادیر موجود انجام می‌شود. روش‌های رایج عبارت‌اند از:
		
		\begin{itemize}
			\item \textbf{جهش جابه‌جایی (\lr{Swap Mutation}):}
			دو موقعیت تصادفی انتخاب شده و مقدارشان جابه‌جا می‌شود.
			\newline
			مثال:
			\newline
			قبل از جهش: 1 2 3 4 5 6   (جابجایی موقعیت‌های ۲ و ۵)
			\newline
	بعد از جهش: 1 5 3 4 2 6
			\item \textbf{جهش معکوس (\lr{Reverse Mutation}):}
			یک بازه تصادفی انتخاب شده و مقادیر آن معکوس می‌شوند.
			\newline
			مثال:
			\newline
			قبل از جهش: 1 2 3 | 4 5 6 | 7 8 9  (معکوس کردن بازه وسط)
			\newline
			بعد از جهش: 1 2 3 | 6 5 4 | 7 8 9
			
			\item \textbf{جهش درج (\lr{Insertion Mutation}):}
			یک مقدار از موقعیت تصادفی حذف شده و در موقعیت دیگری درج می‌شود.
			
			مثال:
			
			قبل از جهش: 1 2 3 4 5 6  (انتقال عدد ۳ بعد از ۵)
			
			بعد از جهش: 1 2 4 5 3 6
			
		\end{itemize}
	\end{enumerate}
	\end{parts}
	
	\question
	در هنگام استفاده از الگوریتم ژنتیک و ساخت جمعیت اولیه اندازه کروموزوم و تعداد ژن‌های آن ثابت و وابسته به پارامترهای مسئله است. در پایان الگوریتم نیز اندازه کروموزوم و تعداد ژن آن باید با شروع کار الگوریتم برابر و ثابت مانده باشد. در اجرای یک الگوریتم ژنتیک (GA) روی رشته‌های بیتی، چندین خاصیت تغییرناپذیری
	 (\lr{Invariance Properties}) وجود دارند که باید حفظ شوند. این ویژگی‌ها تضمین می‌کنند که اولاً الگوریتم به طور مؤثر جستجو کرده است و ثانیاً عملکرد پایدار و قابل‌پیش‌بینی خواهد داشت. در ادامه، این خصوصیات و تأثیر آن‌ها بر کارایی الگوریتم بررسی می‌شود:
	 
	 \begin{itemize}
	 	\item \textbf{تغییرناپذیری تحت جای‌گشت بیت‌ها (\lr{Bit Permutation Invariance}):}
	 	اگر یک مسئله با جای‌گشت موقعیت‌های بیت‌ها تغییری نکند، پس اجرای الگوریتم ژنتیک نیز نباید وابسته به ترتیب بیت‌ها باشد.
	 	
	 	به‌عنوان‌مثال:
	 	
	 	اگر دو رشته بیتی 1100 و 0011  دارای مقدار برازش(یا مقدار تناسب) یکسانی باشند، الگوریتم نباید به ترتیب بیت‌ها حساس باشد، بلکه باید فقط الگوی کلی ژن‌ها را مدنظر قرار دهد. این ویژگی کمک می‌کند تا الگوریتم روی تمام فضای جستجو به‌طور یکنواخت عمل کند و وابسته به نحوه‌ی کدگذاری مسئله نباشد. اگر این خاصیت حفظ نشود، ممکن است الگوریتم به برخی ساختارهای خاص در رشته‌های بیتی تمایل پیدا کند و جستجو مناسب نباشد.
	 	\item \textbf{تغییرناپذیری تحت مقداردهی اولیه تصادفی (\lr{Initial Population Invariance}):}
	 	نتیجه‌ی الگوریتم نباید به توزیع خاصی از مقداردهی اولیه وابسته باشد، بلکه باید همواره به یک جواب بهینه یا نزدیک بهینه همگرا شود.
	 	
	 	به‌عنوان‌مثال:
	 	
	 	دو اجرای الگوریتم ژنتیک با مقداردهی اولیه‌ی تصادفی مختلف نباید نتایج کاملاً متفاوتی داشته باشند، بلکه باید به نقاط بهینه مشابهی همگرا شوند. با این اتفاق قابلیت تکرارپذیری 
	 	(\lr{Reproducibility}) افزایش می‌یابد. اگر این خاصیت رعایت نشود، الگوریتم ممکن است به پاسخ‌های مختلف و ناسازگار در اجراهای مختلف برسد.
	 	
	 	\item \textbf{تغییرناپذیری تحت تغییر مقیاس تابع برازش (\lr{Fitness Scale Invariance}):}
	 	عملکرد الگوریتم نباید به تحولات خطی در تابع برازش حساس باشد.
	 	
	 	به‌عنوان‌مثال:
	 	اگر تابع برازش f(x) را به صورت
	 		\[\mathrm{g} (x) = a \mathrm{f} (x) + b \]
	 	که در آن(a > 0  و b  یک مقدار ثابت است) تغییر دهیم، نباید رفتار الگوریتم عوض شود. اگر این ویژگی حفظ نشود، مقادیر برازش بزرگ یا کوچک می‌توانند روی نحوه‌ی انتخاب و عملکرد اپراتورهای ژنتیکی تأثیر منفی بگذارند. معمولاً نرمال‌سازی تابع برازش می‌تواند این مشکل را برطرف کند.
	 	
	 	\item \textbf{تغییرناپذیری تحت بازآرایی کروموزوم‌ها (\lr{Chromosome Encoding Invariance}):}
	 	نتایج الگوریتم نباید به نوع کدگذاری ژن‌ها وابسته باشد.
	 	
	 	به‌عنوان‌مثال:
	 	
	 	اگر برای حل یک مسئله می‌توان از دو نوع کدگذاری باینری 0001  و 1110 (مثلاً با تعریف‌های متفاوت از بیت‌ها) استفاده کرد، عملکرد الگوریتم نباید وابسته به این انتخاب باشد. همچنین بهینه‌سازی نباید محدود به نوع خاصی از نمایش کروموزومی باشد. با این کار افزایش انعطاف‌پذیری الگوریتم ژنتیک برای حل مسائل مختلف رخ میدهد.
	 	
	 	\item \textbf{تغییرناپذیری تحت تغییرات جمعیت (\lr{Population Size Invariance}:)}
	 	عملکرد کلی الگوریتم باید با تغییر اندازه‌ی جمعیت تغییر محسوسی نداشته باشد (تا حدی معقول).
	 	 
	 	به‌عنوان‌مثال:
	 	
	 	اگر یک الگوریتم با اندازه‌ی جمعیت 50 و یک اجرای دیگر با اندازه‌ی 100 انجام شود، نتایج نباید کاملاً متفاوت باشند، بلکه باید هر دو به یک جواب بهینه مشابه همگرا شوند. پایداری الگوریتم در برابر تنظیمات مختلف و کاهش حساسیت الگوریتم به هایپرپارامترهای تنظیمی از این جهت است. 
	 	
	 	\item \textbf{  تغییرناپذیری نسبت به معکوس کردن بیت‌ها (\lr{Bit Flip Invariance}):}
	 	معکوس کردن مقدار بیت‌ها (تبدیل ۰ به ۱ و برعکس) تأثیری بر عملکرد الگوریتم نباید داشته باشد.
	 	اگر این خاصیت حفظ نشود، الگوریتم ممکن است در جهت‌های نامناسب جستجو کند و زمان بیشتری برای همگرایی نیاز داشته باشد.
	 	
	 	\item \textbf{ تغییرناپذیری نسبت به تغییر مقیاس (\lr{Scale Invariance}):}
	 	تغییر مقیاس در تابع برازش 
	 	(\lr{Fitness Function}) نباید تأثیری بر رفتار الگوریتم داشته باشد.
	 	
	 	به‌عنوان‌مثال: 
	 	
	 	اگر تابع برازش را در یک مسئله بهینه‌سازی در مقیاس‌های مختلف (مثلاً ضرب در یک ثابت) تغییر دهیم، الگوریتم باید همچنان به سمت جواب بهینه همگرا شود.
	 	
	 	\item \textbf{تغییرناپذیری نسبت به چرخش (\lr{Rotation Invariance}):}
	 	چرخش در فضای جستجو (مانند تغییر جهت‌های جستجو) نباید تأثیری بر عملکرد الگوریتم داشته باشد. اگر این خاصیت حفظ نشود، الگوریتم ممکن است در جهت‌های خاصی از فضای جستجو گیر کند و نتواند به طور کامل فضای جستجو را بررسی کند.
	 	
	 	\item \textbf{ تغییرناپذیری نسبت به انتقال (\lr{Translation Invariance}):}
	 	انتقال در فضای جستجو (مانند جابه‌جایی نقطه شروع) تأثیری بر عملکرد الگوریتم نباید داشته باشد. حفظ این خاصیت باعث می‌شود الگوریتم به نقطه شروع اولیه حساس نباشد و عملکرد پایدارتری داشته باشد.
	 	\newpage
	 	به‌عنوان‌مثال: 
	 	
	 	در مسئله‌ای مانند بهینه‌سازی تابع
	 	 \lr{Sphere}، انتقال نقطه شروع نباید بر نتیجه نهایی تأثیر بگذارد.
	 	
	 	\item \textbf{تغییرناپذیری نسبت به تغییرات کوچک در جمعیت (\lr{Population Perturbation Invariance}):}
	 	تغییرات کوچک در جمعیت اولیه (مانند جهش‌های کوچک) نباید تأثیری بر رفتار کلی الگوریتم نداشته باشد. اگر این خاصیت حفظ نشود، الگوریتم ممکن است به دلیل تغییرات کوچک در جمعیت اولیه، به سمت جواب‌های زیر بهینه همگرا شود.
	 	
	 	به‌عنوان‌مثال: 
	 	
	 	در مسئله‌ای مانند مسئله کوله‌پشتی، تغییرات کوچک در جمعیت اولیه نباید منجر به نتایج کاملاً متفاوت شود.
	 	
	 	
	 	
	 	
	 	
	 \end{itemize}

\end{questions}

				
	
	\newpage
	\section{
		درک و حل مسائل با الگوریتم ژنتیک}
	\begin{questions}
		\question
		\begin{parts}
			\part
			 اگر هیچ گره‌ای نباید دو بار دیده شود، یک کروموزوم باید باید یک دور بین همه‌ی گره‌ها باشد که این دور شامل طی ترتیب طی کردن ۱۰ گره یا معادل طی کردن ۱۰ یال است. پس کروموزوم ما شامل ۱۰ ژن است.
			\part
			 اینکه بین کدام شهرها ارتباط وجود داشته باشد پیش‌فرض‌های مسئله است اما به طور کلی می‌توان گفت اگر گراف کامل و بدون طوقه باشد، از هر گره‌ای به همه‌ی گره‌های دیگر یال وجود دارد. ما در نظر گرفتیم این یال‌ها جهت‌دار است پس اگر از یک گره به گره‌ی دیگر رفت برگشت نیازی نیست. با این اوصاف تعداد کل ژن‌های ممکن 
			 $n\times \frac{n-1}{2}$
			 یال می‌شود. که اینجا 
			 $n=10$
			  است پس 
			  $10\times \frac{9}{2}=45$
			  ژن وجود دارد.
		\end{parts}
		
		\question
		\begin{parts}
			\part ژن‌ها  را به تابع 
			fitness
			می‌بریم:
			\[\mathrm{fit} (x_1) = 6+5-4-1+3+5-3-2=9 \]
			\[\mathrm{fit} (x_2) = 8+7-1-2+6+6-0-1=23\]
			\[\mathrm{fit} (x_3) = 2+3-9-2+1+2-8-5=-16\]
			\[\mathrm{fit} (x_4) = 4+1-8-5+2+0-9-4=-19 \]

			به ترتیب
			$x_2$، $x_1$،$x_3$ و $x_4$
			برازنده هستند.
			
			\part عملیات ترکیب
			\begin{itemize}
				\item
				ترکیب نقطه‌ای: در این روش به دو فرزند جدید می‌رسیم.
				\[x_{21} = 8712|3532\]
				\[x_{21}=6541|6601\]
				\item
				ترکیب دو نقطه‌ای: با استفاده از این روش به دو فرزند جدید می‌رسیم. ما فرض می‌کنیم منظور از نقاط b و f یعنی بعد از این نقاط ترکیب اتفاق می‌افتد
				\[x_{131} = 65|9212|35\]
				\[x_{313}=23|4135|85\]
				\item 
				ترکیب یکنواخت: برای انجام این ترکیب نیازمند به یک ماسک هستیم. این ماسک یک ژن تصادفی با مقادیر دودویی است که نشانگر این است که آن ژن را از کروموزوم اول بگیریم یا دوم. که انتخاب اول یا دوم هم احتمال است. ما با استفاده از
				
				
				\lstinputlisting[language=Python, caption= تولید ماسک تصادفی]{./scripts/mask.py}
				
				
				
				یک رشته‌ی تصادفی از ۰ و ۱ تولید می‌کنیم. ما فرض می‌کنیم ۰  معادل رشته‌ی اول و ۱ معادل رشته‌ی سوم باشد.
				
				\[\mathrm{mask} = 01001010\]
				\[x_{13} = 8|3|12|1|6|8|1\]
				\[x_{31}=2|7|92|6|2|0|5\]
			\end{itemize}
			\part
			برازش فرزندان: با استفاده از تکه کد زیر برازندگی هر فرزند را محاسبه می‌کنیم:
			
			
			\lstinputlisting[language=Python, caption= محاسبه‌ی برازندگی]{./scripts/fitness.py}
			
			\[\mathrm{fit} (x_{21} )= 87123532=15\]
			\[\mathrm{fit} (x_{21})= 65416601=17\]
			\[\mathrm{fit} (x_{131}) = 65921235 = -5\]
			\[\mathrm{fit} (x_{313}) = 23413585 = -5\]
			\[\mathrm{fit} (x_{23}) = 83121681 = 6\]
			\[\mathrm{fit} (x_{32}) = 27926205 =1\]
			تعبیر بهتر شدن و بدتر شدن تعبیر نا دقیقی است. ما دو شاخص را برای بهتر شدن و بدتر شدن در نظر می‌گیریم.
			\begin{enumerate}
				\item بالاترین برازندگی: در والدها بالاترین برازندگی ۲۳ بود که به ۱۷ کاهش یافت یعنی بدتر شده.
				\item میانگین برازندگی: در شرایط قبلی برازندگی معادل
				$\frac{9+23-16-19}{4}=\frac{-3}{4} =-0.75 $
				می‌شود و در فرزندان 
				$\frac{15+17-5-5+6+1}{6}=\frac{29}{6} \approx4.83 $
				می‌شود که رشد قابل توجهی است.
			\end{enumerate}
			\part
			برای بیشینه کردن برازندگی، ژن‌های
			\lr{a}، 
			\lr{b}،
			\lr{e} و
			\lr{f}
			باید مقدار ۹ داشته باشند و 
			\lr{c}، 
			\lr{d}،
			\lr{g} و
			\lr{h}
			باید مقدار ۰ را داشته باشند. برازندگی بهینه برابر 
			$4 \times 9 - 0 = 36$
			می‌شود.
			\part
			ما سعی کردیم بهترین ترکیب را بسیازیم  و آن
			$x_{\mathrm{optimal}}= 87116601$
			خواهد بود که برازندگی آن ۲۴ خواهد شد. پس نمی‌توان بدون جهش به نقطه‌ی بهینه رسید و حداقل ۱۲ تا فاصله با نقطه‌ی برازندگی وجود خواهد داشت.
		\end{parts} 
		\question
		kjhghghghghg
		\begin{parts}
			\part\label{p2-3-a}
			مقدار برازندگی به ازای هر 
			\lr{x}:
			\[\mathrm{fit} (x_{1}) = 1-4+7=4\]
			\[\mathrm{fit} (x_{2}) = 8-16+7=-1\]
			\[\mathrm{fit} (x_{3}) = 27-36+7=-2\]
			\[\mathrm{fit} (x_{4}) = 64-64+7=7\]
			\part
			بله. می‌توانیم با اضافه کردن 
			$\forall c : c \ge 2$
			همه‌ی مقدارها را نامنفی کنیم.
			مثلا اگر 
			$c=3$ 
			در نظر بگیریم رابطه‌ی برازندگی 
			$\mathrm{fit} (x) = x^3 - 4 x^2 + 10$
			خواهد شد.
			
			\part به هر برازندگی مقدار ثابت ۲ اضافه می‌شود پس 
			\[\mathrm{Total Fitness} = (4+3)\times 2+(-1+3)\times 3+(-2+3)\times3+(7+3)\times2\]
			\[=14+6+3+20=43\]
			\part 
			مقدار برازندگی نسبی برای هر نمونه‌ی  x به صورت زیر خواهد شد:
			
			\[ P(x=1) = \frac{7}{43} = 0.1628 \]  
			\[P(x=2)=\frac{2}{43}=0.0465\]
			\[P(x=3)=\frac{1}{43}=0.0233\]
			\[P(x=4)=\frac{10}{43}=0.2326\]
			می‌توانیم آن را به صورت یک گردونه هم نشان دهیم
			\begin{figure}[H]
				\begin{center}
\begin{tikzpicture}[x=0.05\textwidth, y=0.05\textwidth]
\pie{
	16/\rl{نفر اول}  ,
	16/دوم,
	5/سوم,
	5/چهارم,
	5/ پنجم,
	3/ششم,
	2/ هفتم,
	2/هشتم,
	23/نهم,
	23/ دهم}
	\end{tikzpicture}
	\caption{گردونه‌ی شانس برای این نمونه از جمعیت}
	\end{center}
\end{figure}
			

			
			\part 
			مزیت تابع جدید این است که به ازا‌ی هر مقدار 
			\lr{x}،
			تابع برازندگی همواره نامنفی است. برای محاسبه‌ی 
			$g(x)$
			تمام مقدادیر بدست آمده در بخش
			\ref{p2-3-a}
			را به توان ۲ می‌رسانیم.
			\[\mathrm{fit} (x_{1}) =4^2=16\]
			\[\mathrm{fit} (x_{2}) =(-1)^2=1\]
			\[\mathrm{fit} (x_{3}) =(-2)^2=4\]
			\[\mathrm{fit} (x_{4}) =7^2=49\]
			\part
			\begin{itemize}
				\item 
				\textbf{
				فشار انتخاب}:
				فشار انتخاب یعنی درجه‌ی اینکه افراد برازنده‌تر چقدر شانس زنده ماندن دارند.  برعکس اضافه کردن مقدار ثابت، در «به توان رساندن» فشار انتخاب زیاد می‌شود. البته این تا حدودی بستگی به روش انتخاب هم دارد. مثلا اگر از الگوریتم انتخاب رتبه پایه
				\footnote{\lr{rank-based selection}}
				استفاده کنیم دیگر این مسئله جدی نیست.
				
				\item 
				\textbf{
				همگرایی}:
				می‌توان گفت با افزایش فشار انتخاب، همگرایی سریع‌تر می‌شود اما خطر گیر کردن در یک نقطه‌ی بهینه‌ی محلی وجود دارد.
				
				\item 
				\textbf{
				تنوع:}
				افزایش فشار انتخاب باعث کاهش تنوع و همگرایی سریع به یک قله‌ی محلی خاص می‌شود که ممکن است بهترین نباشد. با افزایش فشار انتخاب تنوع در انتخاب گونه‌ها را از دست می‌دهیم.
			\end{itemize}
			
		\end{parts}
		
	\end{questions}
	
	\newpage
	\section[
	پیاده‌سازی، ارزیابی و تجزیه‌ و تحلیل الگوریتم ژنتیک]{پیاده‌سازی، ارزیابی و تجزیه‌ و تحلیل الگوریتم ژنتیک جهت انتخاب بهترین ویژگی برای مسئله‌ی واقعی دسته‌بندی مشتریان} 
\input{phase3}
\end{document}