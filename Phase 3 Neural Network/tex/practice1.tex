\section{مفاهیم و حل مسئله}
\begin{enumerate}
	\item بله، هر نورون در یک شبکهٔ عصبی حامل نوعی اطلاعات است؛ اما ماهیت و میزان «وضوح» این اطلاعات بسته به عمق لایه و ویژگی‌های بنیادین شبکه متفاوت است. 
	
	
	 چهار ویژگی بنیادی و سلسله‌مراتبی بودن نمایش:
	
	\begin{enumerate}
		\item \textbf{توابع غیرخطی (Nonlinearity)}
		\begin{itemize}
			\item هر نورون پس از ترکیب خطی ورودی‌ها (ضرب وزن‌ها + بایاس) خروجی را از طریق تابعی مانند \lr{ReLU}، \lr{sigmoid} یا \lr{tanh} عبور می‌دهد.
			\item بدون غیرخطی‌سازی، شبکه عملاً یک عملگر خطی بزرگ خواهد بود و قادر به تشخیص زیرویژگی‌های پیچیده نیست.
			\item تابع فعال‌سازی باعث می‌شود هر نورون تنها در صورت وقوع یک الگوی خاص «فعال» شود و در نتیجه به‌عنوان یک تشخیص‌دهندهٔ ساده عمل کند.
		\end{itemize}
		
		\item \textbf{نمایش توزیع‌شده (\lr{Distributed Representation})}
		\begin{itemize}
			\item برخلاف سیستم‌های سمبلیک که هر مفهوم را با یک واحد منفرد نمایش می‌دهند، شبکه‌های عصبی مفاهیم را به‌صورت همزمان در بردار فعال‌سازی تعداد زیادی نورون کدگذاری می‌کنند.
			\item این پراکندگی اطلاعات باعث افزایش مقاومت شبکه در برابر نویز و آسیب به نورون‌های منفرد می‌شود.
			\item هر نورون سهم جزئی اما معنادار در تشخیص زیرویژگی‌های ساده یا انتزاعی دارد.
		\end{itemize}
		
		\item \textbf{یادگیری گرادیان‌محور (\lr{Gradient‐based Learning})}
		\begin{itemize}
			\item با استفاده از الگوریتم پس‌انتشار (\lr{Backpropagation})، وزن‌ها و بایاس هر نورون به‌روزرسانی می‌شود تا خطای خروجی به کمترین مقدار برسد.
			\item در طی آموزش، هر نورون به زیرویژگی‌هایی پاسخ می‌دهد که برای کاهش خطا در مسئلهٔ مشخص مفیدند.
			\item در پایان آموزش، وزن‌های ورودی هر نورون تعیین می‌کنند که آن نورون به چه الگو یا ویژگی‌ حساس باشد.
		\end{itemize}
		
		\item \textbf{سلسله‌مراتب ویژگی‌ها (\lr{Hierarchical Feature Learning})}
		\begin{itemize}
			\item لایه‌های ابتدایی شبکه‌های عمیق معمولاً به زیرویژگی‌های ساده مانند لبه‌های عمودی/افقی یا بافت‌ها حساس‌اند.
			\item لایه‌های میانی ترکیب این زیرویژگی‌ها را انجام داده و الگوهای پیچیده‌تر  را می‌آموزند.
			\item در لایهٔ خروجی (مثلاً نورون‌های \lr{softmax}) احتمال تعلق هر ورودی به یک کلاس نهایی (مثلاً «گربه» یا «سگ») کدگذاری می‌شود.
		\end{itemize}
	\end{enumerate}
	
	\item در شبکه‌های عصبی، «دانش» در قالب پارامترها (وزن‌ها و بایاس‌ها) ذخیره می‌شود و از طریق فرآیند آموزش شکل می‌گیرد؛ در ادامه، یک پاسخ یکپارچه و مرتب‌شده ارائه شده است:
	
	\begin{enumerate}
		\item \textbf{شکل‌گیری دانش در شبکه‌های عصبی}
		\begin{enumerate}
			\item \textbf{تعریف ساختار شبکه (\lr{Architecture}):}  
			انتخاب تعداد لایه‌ها (\lr{Input, Hidden, Output})، نوع آن‌ها (\lr{fully-connected}، کانولوشن، بازگشتی و …) و تعداد نورون در هر لایه.
			\item \textbf{مقداردهی اولیه پارامترها (\lr{Initialization}):}  
			وزن‌ها و بایاس‌ها معمولاً با توزیع‌های تصادفی (مثل \lr{Xavier} یا \lr{He}) مقداردهی می‌شوند.
			\item \textbf{انتشار رو به جلو (\lr{Forward Propagation}):}  
			برای هر ورودی \(x\)، در هر لایه:
			\[
			z^{(\ell)} = W^{(\ell)}\,a^{(\ell-1)} + b^{(\ell)}, 
			\quad
			a^{(\ell)} = \sigma\bigl(z^{(\ell)}\bigr)
			\]
			در نهایت \(a^{(L)}\) خروجی نهایی شبکه است.
			\item \textbf{محاسبه خطا (\lr{Loss Calculation}):}  
			با تابع هزینه \(L\bigl(y_{\text{pred}},\,y_{\text{true}}\bigr)\)، مانند MSE برای رگرسیون یا Cross-Entropy برای طبقه‌بندی.
			\item \textbf{پس انتشار خطا (\lr{Backpropagation}):}  
			مشتق تابع هزینه را نسبت به پارامترها محاسبه می‌کنیم:
			\[
			\frac{\partial L}{\partial W^{(\ell)}},\quad
			\frac{\partial L}{\partial b^{(\ell)}}
			\]
			\item \textbf{به‌روزرسانی پارامترها (\lr{Optimization}):}  
			با الگوریتم‌هایی مثل \lr{Gradient Descent} یا \lr{Adam}:
			\[
			W^{(\ell)} \leftarrow W^{(\ell)} - \eta\,\frac{\partial L}{\partial W^{(\ell)}}, 
			\quad
			b^{(\ell)} \leftarrow b^{(\ell)} - \eta\,\frac{\partial L}{\partial b^{(\ell)}}
			\]
			این چرخه تا رسیدن به همگرایی تکرار می‌شود.
		\end{enumerate}
		
		\item \textbf{فرمول‌بندی «معادل بودن» دو شبکه عصبی}
		\begin{enumerate}
			\item \textbf{معادل تابعی (\lr{Exact Functional Equivalence})}  
			دو شبکه \(N(x)=f_{\theta_N}(x)\) و \(M(x)=f_{\theta_M}(x)\) دقیقاً معادل‌اند اگر:
			\[
			\forall x\in X,\quad N(x)=M(x).
			\]
			\item \emph{معادل ساختاری تحت تبدیلات (\lr{Structural Equivalence})}  
			در لایه‌های \lr{Dense}، جابجایی نورون‌ها (پرموتیشن \(\pi\)) همراه با جابجایی سطرها/ستون‌های متناظر در \(W,b\)، خروجی را تغییر نمی‌دهد.
			\item \emph{تقریب معادل (\lr{Approximate Equivalence})}  
			با فاصلهٔ خروجی \(d(x)=\|N(x)-M(x)\|_p\):
			\[
			\forall x\in X,\;d(x)<\epsilon
			\quad\text{یا}\quad
			\mathrm{KL}\bigl(N(x)\Vert M(x)\bigr)<\delta.
			\]
		\end{enumerate}
		
		\item \textbf{مثال ریاضی}
		\begin{enumerate}
			\item \textbf{حالت سادهٔ خطی:}  
			دو شبکه خطی با یک لایه پنهان و \(\sigma(z)=z\):
			\[
			N(x)=W_2\,(W_1\,x+b_1)+b_2,\quad
			M(x)=W_2'\,(W_1'\,x+b_1')+b_2'.
			\]
			آن‌ها معادل‌اند اگر:
			\[
			W_2W_1 = W_2'W_1', 
			\quad
			W_2b_1 + b_2 = W_2'b_1' + b_2'.
			\]
			\item \emph{اشاره‌ای به حالت غیرخطی:}  
			در شبکه‌های غیرخطی (مثلاً \lr{ReLU})، تبدیلات پیچیده‌ترند؛ اما با ادغام \lr{BatchNorm} یا تبدیلات جبری می‌توان مشابهت رفتار را نشان داد.
		\end{enumerate}
		
	\end{enumerate}
	
\end{enumerate}
